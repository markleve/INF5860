{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>Note: Do NOT run any of these cells/scripts on UIO IFI computers! (Explanation below)  </b></span> \n",
    "\n",
    "In this mandaroty exercise you are implementing an image captioning network. For training and validation data you will need images with corresponding descriptions. The dataset that you will use is the \"Common Object in Context\" (COCO) 2017. You will also need pretrained weights form the VGG16 network.\n",
    "\n",
    "If you are working on a UIO IFI computer data will be avaibale for you on the project disk. The *path* is given to you in the assigment. The dataset is large (~18GB) and every student cannot download it on the UIO IFI computers. It also takes too long time to produce VGG16 features which is needed for the imaging captioning task. However, if you are working on your own computer, you will need to follow the steps in this notebook to be able to complete the exercise. <span style=\"color:orange\">Downloading the dataset, generating the vocabulary and processing VGG16 features will take a long time. It will depend on your internet connection and compute power, but it can be a good idea to run this notebook over night. </span> \n",
    "\n",
    "This notebook will help you with:\n",
    "- Downloading and unzipping training and validation data from the COCO 2017 dataset\n",
    "- Generating a vocabulary dictionary holding information about the captions and the corresponding tokens.\n",
    "- Downloading and unzipping the VGG16 weights\n",
    "- Produce and store features from the secound fully connected layer in the VGG16 network for all train and validation images.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Links:\n",
    "- [Step1: Download COCO dataset](#Task1)\n",
    "- [Step2: Generate vocabulary](#Task2)\n",
    "- [Step3: Download VGG16 weights](#Task3)\n",
    "- [Step4: Produce VGG16 features](#Task4)\n",
    "\n",
    "\n",
    "Software version:\n",
    "- Python 3.6\n",
    "- TensorFlow 1.4.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "<a id='Task1'></a>\n",
    "### Step1: Download COCO dataset\n",
    "\n",
    "The data can be found in folder \"data/coco\". Subfolder e.g. \"train2017\" contains the training images as jpg files.\n",
    "\n",
    "\n",
    "**Note**: If the process failed at some point, you may need to go into the \"data/coco\" folder and delete the files which were not downloaded correctly before trying again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://images.cocodataset.org/zips/train2017.zip\n",
      "Data has apparently already been downloaded and unpacked.\n",
      "Downloading http://images.cocodataset.org/zips/val2017.zip\n",
      "Data has apparently already been downloaded and unpacked.\n",
      "Downloading http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "from utils import coco\n",
    "\n",
    "#Create dataClass\n",
    "myCocoDataClass = coco.CocoImagesDataClass()\n",
    "\n",
    "# Set data directory\n",
    "data_dir=\"data/coco/\"\n",
    "myCocoDataClass.set_data_dir(data_dir)\n",
    "\n",
    "\n",
    "# Download coco dataset\n",
    "myCocoDataClass.maybe_download_and_extract_coco()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='Task2'></a>\n",
    "### Step2: Generate vocabulary ###\n",
    "\n",
    "\n",
    "The vocabulary will be stored as a pickle file at \"data/coco/vocabulary\"\n",
    "\n",
    "**Note**: If the process failed at some point, you may need to go into the \"data/coco/vocabulary\" folder and delete the file if it was not downloaded correctly before trying again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file \"vocabulary.pickle\" has already been produced.\n"
     ]
    }
   ],
   "source": [
    "# Load records\n",
    "myCocoDataClass.load_records(trainSet=True)\n",
    "myCocoDataClass.load_records(trainSet=False)\n",
    "\n",
    "# Generate vocabulary\n",
    "myCocoDataClass.generate_vocabulary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='Task3'></a>\n",
    "### Step3: Download vgg16 weights ###\n",
    "\n",
    "The pretrained weights will be stored in folder \"model/VGG16\" as a .ckpt file\n",
    "\n",
    "**Note**: If the process failed at some point, you may need to go into the \"model\\VGG16\" folder and delete the file if it was not downloaded correctly before trying again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "# Download vgg16 weights\n",
    "myCocoDataClass.maybe_download_and_extract_vgg16weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='Task4'></a>\n",
    "### Step4: Produce VGG16 features ###\n",
    "\n",
    "\n",
    "The data can be found in folder \"data/coco\". The subfolder e.g. \"Train2017_vgg16_fc7\" contains pickle files for each training example.\n",
    "\n",
    "**Note**: If the process failed at some point, you may need to go into the \"data/coco\" folder and delete \"train2017_vgg16_fc7\" and \"val2017_vgg16_fc7\" before trying again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from data/coco/CNN/vgg_16.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generate: Train pickle files:   0%|          | 0/1849 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#Produce pickle files with VGG16 features\n",
    "myCocoDataClass.produceVgg16Fc7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
